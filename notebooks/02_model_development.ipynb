{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae610fe3",
   "metadata": {},
   "source": [
    "# 2. Model Development and Training\n",
    "\n",
    "This notebook details the architecture, compilation, and training process for the two models developed in this project:\n",
    "1.  **Model #1:** A custom Convolutional Neural Network (CNN) built from scratch.\n",
    "2.  **Model #2:** A more advanced model utilizing transfer learning with a pre-trained MobileNetV2 base.\n",
    "\n",
    "All training is performed on the V2 (cropped) dataset. The actual training is executed via the `src/train.py` script for reproducibility, but the model definitions and training setup are documented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "IMAGE_SIZE = (150, 150)\n",
    "NUM_CLASSES = 4 # rock, paper, scissors, none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53040c0e",
   "metadata": {},
   "source": [
    "## 2.1. Model #1: Custom CNN from Scratch\n",
    "\n",
    "This model serves as a baseline to understand the difficulty of the task without pre-trained knowledge.\n",
    "\n",
    "### Architecture Justification\n",
    "-   **Convolutional Blocks (3x):** The model uses a stack of three `Conv2D` and `MaxPooling2D` layers. The number of filters increases (32 -> 64 -> 128) to allow the network to learn increasingly complex features, from simple edges in the first layer to more intricate shapes in deeper layers.\n",
    "-   **MaxPooling:** After each convolution, max pooling is used to downsample the feature maps, making the learned features more robust to variations in position and reducing the number of parameters.\n",
    "-   **Flatten & Dense Layers:** The 2D feature maps are flattened into a 1D vector to be processed by a fully-connected `Dense` layer.\n",
    "-   **Dropout:** A `Dropout` layer with a rate of 0.4 is included before the final output layer. This is a crucial regularization technique to combat overfitting by randomly deactivating neurons during training, forcing the network to learn more redundant and robust representations.\n",
    "-   **Output Layer:** The final `Dense` layer has `NUM_CLASSES` neurons with a `softmax` activation function to output a probability distribution over the four classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scratch_model(input_shape, num_classes):\n",
    "    \"\"\"Defines the custom CNN architecture.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Instantiate and print summary\n",
    "scratch_model = create_scratch_model(input_shape=IMAGE_SIZE + (3,), num_classes=NUM_CLASSES)\n",
    "scratch_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f971a",
   "metadata": {},
   "source": [
    "## 2.2. Model #2: Transfer Learning with MobileNetV2\n",
    "\n",
    "This model leverages a pre-trained network to achieve higher performance with less data.\n",
    "\n",
    "### Architecture Justification\n",
    "-   **Base Model (MobileNetV2):** MobileNetV2 was chosen as the base model. It is a powerful, state-of-the-art architecture that is also lightweight and efficient. It has already been trained on the massive ImageNet dataset, learning a rich hierarchy of visual features.\n",
    "-   **Freezing the Base:** The convolutional base of MobileNetV2 is frozen (`base_model.trainable = False`). This prevents the pre-trained weights from being updated during initial training, preserving the valuable learned features. We only want to train our new classifier head.\n",
    "-   **Custom Classifier Head:**\n",
    "    -   `GlobalAveragePooling2D`: This layer is added after the base model to efficiently downsample the feature maps into a single vector, drastically reducing the number of parameters compared to a `Flatten` layer.\n",
    "    -   `Dropout`: A dropout layer is still used to regularize our new classifier head and prevent it from overfitting.\n",
    "    -   `Dense` Output Layer: The final layer is identical to the scratch model, tailored for our 4-class problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e713a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_model(input_shape, num_classes):\n",
    "    \"\"\"Defines the transfer learning architecture.\"\"\"\n",
    "    base_model = MobileNetV2(input_shape=input_shape,\n",
    "                             include_top=False,\n",
    "                             weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Instantiate and print summary\n",
    "transfer_model = create_transfer_model(input_shape=IMAGE_SIZE + (3,), num_classes=NUM_CLASSES)\n",
    "transfer_model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
